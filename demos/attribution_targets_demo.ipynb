{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Attribution Targets](https://raw.githubusercontent.com/safety-research/circuit-tracer/main/demos/img/attribution_targets/attribution_targets_banner.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qa5r1-7RmS8j"
   },
   "source": [
    "# Attribution Targets\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/safety-research/circuit-tracer/blob/main/demos/attribution_targets_demo.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial walks through the **attribution targets API**, demonstrating how to attribute back from arbitrary tokens, functions thereof, or abstract concept directions in the residual stream.\n",
    "\n",
    "The `AttributionTargets` class (in `circuit_tracer.attribution.targets`) accepts four input formats:\n",
    "\n",
    "| Input type | Mode | Description |\n",
    "|---|---|---|\n",
    "| `None` | Salient logits | Auto-selects the most probable next tokens via `max_n_logits` / `desired_logit_prob` (default) |\n",
    "| `Sequence[str]` | Token strings | Attribute from explicitly named tokens, e.g. `[\"▁Austin\", \"▁Dallas\"]` |\n",
    "| `torch.Tensor` | Token ID tensor | Attribute from specific vocabulary indices |\n",
    "| `Sequence[TargetSpec]` | Custom target | Attribute from arbitrary residual-stream directions via `CustomTarget(token_str, prob, vec)` |\n",
    "\n",
    "We will demo the use of all four input formats using the capital-city prompt you may be familiar with from other demos: the model must resolve *\"capital of the state containing Dallas\"* via multi-hop reasoning (Dallas → Texas → Austin). After comparing the top features discovered under each mode, we will apply interventions to elucidate two `CustomTarget` examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Colab Environment Setup { display-mode: \"form\" }\n",
    "\n",
    "import sys\n",
    "\n",
    "IN_COLAB = \"google.colab\" in sys.modules\n",
    "\n",
    "def setup_environment():\n",
    "    from google.colab import output\n",
    "    output.enable_custom_widget_manager()\n",
    "\n",
    "    print(\"Setting up Colab environment...\")\n",
    "    %pip install -q uv\n",
    "\n",
    "    # Use uv to install our PR branch for temporary testing, replace w/ commented line once installing from release.\n",
    "    !uv pip install --system --no-cache \"git+https://github.com/speediedan/circuit-tracer.git@attribution-targets\"\n",
    "    # after merged to main, install released version\n",
    "    # !uv pip install --system --no-cache circuit-tracer\n",
    "\n",
    "    from huggingface_hub import notebook_login\n",
    "    notebook_login()\n",
    "\n",
    "if IN_COLAB:\n",
    "    setup_environment()\n",
    "else:\n",
    "    print(\"Running in local environment. Skipping Colab-specific setup.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P8fNhpqzmS8k"
   },
   "outputs": [],
   "source": [
    "# @title Imports { display-mode: \"form\" }\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "import torch\n",
    "\n",
    "from circuit_tracer import ReplacementModel, attribute\n",
    "from circuit_tracer.attribution.targets import CustomTarget\n",
    "from circuit_tracer.utils import create_graph_files\n",
    "from circuit_tracer.utils.demo_utils import (\n",
    "    cleanup_cuda,\n",
    "    display_ablation_chart,\n",
    "    display_attribution_config,\n",
    "    display_token_probs,\n",
    "    display_topk_token_predictions,\n",
    "    display_top_features_comparison,\n",
    "    get_top_features,\n",
    "    get_unembed_vecs,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZN_3kEyfmS8k"
   },
   "source": [
    "## Setup\n",
    "\n",
    "Load the model and define helper functions. We use `google/gemma-2-2b` with the Gemma Scope transcoders, the same configuration used in the other demos. Change `backend` to `'nnsight'` if you prefer the NNSight backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BBsETpl0mS8l"
   },
   "outputs": [],
   "source": [
    "model_name = \"google/gemma-2-2b\"\n",
    "transcoder_name = \"gemma\"\n",
    "backend = \"transformerlens\"  # change to 'nnsight' for the nnsight backend!\n",
    "model = ReplacementModel.from_pretrained(\n",
    "    model_name, transcoder_name, dtype=torch.bfloat16, backend=backend\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VXfD-5GrmS8l"
   },
   "source": [
    "## Basic Attribution Target Modes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section explores the three simplest ways to specify attribution targets:\n",
    "\n",
    "1. **Automatic Salient Logit Targets** (`None`) — the default mode; auto-selects the most probable next tokens.\n",
    "2. **Token-String Targets** (`Sequence[str]`) — attribute from explicit token surface forms.\n",
    "3. **Token-ID Targets** (`torch.Tensor`) — attribute from specific vocabulary indices (pre-tokenized equivalent of string targets).\n",
    "\n",
    "> **Coming up:** After these basic modes, we explore two **custom attribution target** examples that let you attribute back from arbitrary residual-stream directions — a logit *difference* (`logit(Austin) − logit(Dallas)`) and an abstract *semantic concept* (`Capitals − States`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wx2XiXVjmS8l"
   },
   "outputs": [],
   "source": [
    "# Define the prompt, shared attribution parameters, and the three reference tokens (`▁Austin`, `▁Dallas`, `▁Texas`). \n",
    "\n",
    "prompt = \"Fact: the capital of the state containing Dallas is\"\n",
    "token_x, token_y = \"▁Austin\", \"▁Dallas\"\n",
    "\n",
    "# Shared attribution kwargs (apply to all runs)\n",
    "# Note: max_n_logits / desired_logit_prob only apply to salient-logit mode\n",
    "attr_kwargs = dict(\n",
    "    batch_size=256,\n",
    "    max_feature_nodes=8192,\n",
    "    offload=\"disk\" if IN_COLAB else \"cpu\",\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# Resolve token ids for key tokens\n",
    "tokenizer = model.tokenizer\n",
    "idx_x = tokenizer.encode(token_x, add_special_tokens=False)[-1]\n",
    "idx_y = tokenizer.encode(token_y, add_special_tokens=False)[-1]\n",
    "idx_texas = tokenizer.encode(\"▁Texas\", add_special_tokens=False)[-1]\n",
    "\n",
    "# Bind the tokenizer and key tokens for display helpers\n",
    "display_topk = partial(\n",
    "    display_topk_token_predictions,\n",
    "    tokenizer=tokenizer,\n",
    "    key_tokens=[(token_x, idx_x), (token_y, idx_y), (\"▁Texas\", idx_texas)],\n",
    ")\n",
    "\n",
    "# Show baseline token probabilities\n",
    "input_ids = model.ensure_tokenized(prompt)\n",
    "with torch.no_grad():\n",
    "    baseline_logits, _ = model.get_activations(input_ids)\n",
    "\n",
    "key_ids = [idx_x, idx_y, idx_texas]\n",
    "key_labels = [token_x, token_y, \"▁Texas\"]\n",
    "display_token_probs(baseline_logits, key_ids, key_labels, title=\"Baseline probabilities\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RUn1YKnUmS8l"
   },
   "source": [
    "### Automatic Target Selection — Salient Logits (`None`)\n",
    "\n",
    "When `attribution_targets` is `None` (the default), `AttributionTargets` auto-selects the most probable next tokens until `desired_logit_prob` cumulative probability is reached (capped at `max_n_logits`). This is the standard mode used by `attribute_demo.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2tLE4FzdmS8m"
   },
   "outputs": [],
   "source": [
    "graph_salient = attribute(\n",
    "    prompt=prompt, model=model,\n",
    "    max_n_logits=10, desired_logit_prob=0.95,\n",
    "    **attr_kwargs,\n",
    ")\n",
    "print(f\"Salient-logits graph: {len(graph_salient.logit_targets)} targets, \"\n",
    "      f\"{graph_salient.active_features.shape[0]} active features\")\n",
    "\n",
    "# Free CUDA memory before next run\n",
    "cleanup_cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w3cdLLfJmS8m"
   },
   "source": [
    "### Token-String Targets — `Sequence[str]`\n",
    "\n",
    "Pass a list of token strings (e.g., `[\"▁Austin\", \"▁Dallas\"]`) to focus attribution on exactly those logits. Internally, each string is tokenized and its softmax probability and unembedding vector are computed automatically — you only need to supply the surface forms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vh8HPtimmS8m"
   },
   "outputs": [],
   "source": [
    "graph_str = attribute(\n",
    "    prompt=prompt, model=model,\n",
    "    attribution_targets=[token_x, token_y],\n",
    "    **attr_kwargs,\n",
    ")\n",
    "print(f\"String-targets graph: {len(graph_str.logit_targets)} targets, \"\n",
    "      f\"{graph_str.active_features.shape[0]} active features\")\n",
    "\n",
    "# Free CUDA memory before next run\n",
    "cleanup_cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Token-ID Targets — `torch.Tensor`\n",
    "\n",
    "Pass a tensor of vocabulary token IDs to attribute from specific indices. This is the pre-tokenized equivalent of the string-target mode above — internally, the same probabilities and unembedding vectors are computed. Use this mode when you already have token IDs (e.g., from a prior tokenization step) and want to skip the string→ID lookup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the same token IDs as the string-target example above\n",
    "tensor_targets = torch.tensor([idx_x, idx_y])\n",
    "\n",
    "graph_tensor = attribute(\n",
    "    prompt=prompt, model=model,\n",
    "    attribution_targets=tensor_targets,\n",
    "    **attr_kwargs,\n",
    ")\n",
    "print(f\"Tensor-targets graph: {len(graph_tensor.logit_targets)} targets, \"\n",
    "      f\"{graph_tensor.active_features.shape[0]} active features\")\n",
    "\n",
    "# Free CUDA memory before next run\n",
    "cleanup_cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Attribution Targets\n",
    "\n",
    "Beyond the basic modes above, `AttributionTargets` also accepts a `Sequence[TargetSpec]` — fully specified custom targets that let you attribute toward **arbitrary directions** in the residual stream. This makes a vast experimental surface more accessible but we'll explore a couple examples in this tutorial:\n",
    "\n",
    "- **Logit Difference Target** — encodes the direction `logit(Austin) − logit(Dallas)`, surfacing features that drive the model to prefer one token *over* another rather than boosting either in isolation.\n",
    "- **Semantic Concept Target** — encodes an abstract *Capitals − States* direction built from multiple (capital, state) pairs via vector rejection, isolating the *capital-of* relation from shared geography.\n",
    "\n",
    "See the expandable section below if you want a more detailed look at `CustomTarget` definition before we proceed with the examples below.\n",
    "\n",
    "<details>\n",
    "<summary><b>TargetSpec / CustomTarget — field reference</b></summary>\n",
    "\n",
    "The `attribution_targets` argument to `attribute()` accepts a `Sequence[TargetSpec]` for fully custom residual-stream directions. Two convenience types are involved:\n",
    "\n",
    "**`CustomTarget(token_str, prob, vec)`** is a `NamedTuple` with three fields:\n",
    "\n",
    "| Field | Type | Description |\n",
    "|---|---|---|\n",
    "| `token_str` | `str` | Human-readable label for this target (e.g. `\"logit(Austin)−logit(Dallas)\"`) |\n",
    "| `prob` | `float` | Scalar weight — typically the softmax probability of the token, or \\|p(x)−p(y)\\| for a contrast direction |\n",
    "| `vec` | `Tensor (d_model,)` | The direction in residual-stream space to attribute toward |\n",
    "\n",
    "**`TargetSpec`** is a type alias for `CustomTarget | tuple[str, float, torch.Tensor]`. Either form is accepted — a raw 3-tuple is coerced to a `CustomTarget` namedtuple automatically before processing.\n",
    "\n",
    "**Example — raw tuple (coerced automatically):**\n",
    "\n",
    "```python\n",
    "raw: TargetSpec = (\"my-direction\", 0.05, some_tensor)   # plain 3-tuple → TargetSpec\n",
    "graph = attribute(prompt=prompt, model=model, attribution_targets=[raw])\n",
    "```\n",
    "\n",
    "**Example — explicit `CustomTarget` namedtuple:**\n",
    "\n",
    "```python\n",
    "from circuit_tracer.attribution.targets import CustomTarget\n",
    "\n",
    "target = CustomTarget(\n",
    "    token_str=\"logit(Austin)−logit(Dallas)\",\n",
    "    prob=abs(p_austin - p_dallas),        # scalar weight\n",
    "    vec=unembed_austin - unembed_dallas,  # shape: (d_model,)\n",
    ")\n",
    "graph = attribute(prompt=prompt, model=model, attribution_targets=[target])\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "We first define two helper functions for building these custom targets, then construct and attribute from each one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target Builder Helpers\n",
    "\n",
    "We define two helper functions that each return a `CustomTarget` namedtuple.\n",
    "\n",
    "---\n",
    "\n",
    "**`build_custom_diff_target`** — *Logit-difference direction.*\n",
    "\n",
    "Subtracts the unembedding column of token $y$ from that of token $x$:\n",
    "\n",
    "$$\\mathbf{d} = \\mathbf{u}_{x} - \\mathbf{u}_{y}$$\n",
    "\n",
    "and weights the target by the absolute softmax-probability difference $|p(x) - p(y)|$. Attributing toward $\\mathbf{d}$ surfaces features that drive the model to prefer token $x$ *over* token $y$ — a narrower signal than boosting $x$ in isolation.\n",
    "\n",
    "---\n",
    "\n",
    "**`build_semantic_concept_target`** — *Abstract concept direction via vector rejection.*\n",
    "\n",
    "Given paired token groups $A$ (e.g. capital cities) and $B$ (e.g. states), the function strips the \"state\" component from each \"capital\" unembedding vector via orthogonal projection:\n",
    "\n",
    "$$\\mathbf{r}_i = \\mathbf{u}_{a_i} - \\frac{\\mathbf{u}_{a_i} \\cdot \\mathbf{u}_{b_i}}{\\|\\mathbf{u}_{b_i}\\|^2}\\,\\mathbf{u}_{b_i}$$\n",
    "\n",
    "The final concept direction is the mean of these residuals across all pairs:\n",
    "\n",
    "$$\\mathbf{d}_{\\text{concept}} = \\frac{1}{n}\\sum_{i=1}^{n} \\mathbf{r}_i$$\n",
    "\n",
    "**Intuition:** Raw capital-city vectors (Austin, Sacramento, …) are partially explained by their shared geography with their respective states (Texas, California, …). Projecting away the state component leaves a representation of *\"capital-ness\"* that is independent of specific geography. Attributing toward $\\mathbf{d}_{\\text{concept}}$ reveals features the model uses to execute the abstract *capital-of* relation in this context — a strictly more targeted lens than a single logit difference or token string target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_last_position_probs(model, prompt):\n",
    "    \"\"\"Get softmax probabilities at the last token position.\"\"\"\n",
    "    input_ids = model.ensure_tokenized(prompt)\n",
    "    with torch.no_grad():\n",
    "        logits, _ = model.get_activations(input_ids)\n",
    "    return torch.softmax(logits.squeeze(0)[-1], dim=-1)\n",
    "\n",
    "\n",
    "def build_custom_diff_target(model, prompt, token_x, token_y, backend):\n",
    "    \"\"\"Build a CustomTarget for the direction logit(token_x) − logit(token_y).\n",
    "\n",
    "    Returns (custom_target, idx_x, idx_y).\n",
    "    \"\"\"\n",
    "    tokenizer = model.tokenizer\n",
    "    idx_x = tokenizer.encode(token_x, add_special_tokens=False)[-1]\n",
    "    idx_y = tokenizer.encode(token_y, add_special_tokens=False)[-1]\n",
    "\n",
    "    # Extract unembed columns\n",
    "    vec_x, vec_y = get_unembed_vecs(model, [idx_x, idx_y], backend)\n",
    "    diff_vec = vec_x - vec_y\n",
    "\n",
    "    # Weight = |p(token_x) − p(token_y)|, floored at 1e-6\n",
    "    probs = _get_last_position_probs(model, prompt)\n",
    "    diff_prob = max((probs[idx_x] - probs[idx_y]).abs().item(), 1e-6)\n",
    "\n",
    "    custom_target = CustomTarget(\n",
    "        token_str=f\"logit({token_x})-logit({token_y})\",\n",
    "        prob=diff_prob,\n",
    "        vec=diff_vec,\n",
    "    )\n",
    "    return custom_target, idx_x, idx_y\n",
    "\n",
    "\n",
    "def build_semantic_concept_target(model, prompt, group_a_tokens, group_b_tokens, label, backend):\n",
    "    \"\"\"Build a CustomTarget for an abstract concept direction via vector rejection.\n",
    "\n",
    "    For each (capital, state) pair, project the capital vector onto the state\n",
    "    vector and subtract that projection.  The residual is the component of\n",
    "    \"capital-ness\" orthogonal to its state, stripping out shared geography.\n",
    "\n",
    "        v_residual_i = v_cap_i − proj_{v_state_i}(v_cap_i)\n",
    "\n",
    "    The final direction is the mean of these residuals.\n",
    "\n",
    "    Returns CustomTarget.\n",
    "    \"\"\"\n",
    "    assert len(group_a_tokens) == len(group_b_tokens), \"Groups must have equal length for paired differences\"\n",
    "    tokenizer = model.tokenizer\n",
    "    ids_a = [tokenizer.encode(t, add_special_tokens=False)[-1] for t in group_a_tokens]\n",
    "    ids_b = [tokenizer.encode(t, add_special_tokens=False)[-1] for t in group_b_tokens]\n",
    "\n",
    "    vecs_a = get_unembed_vecs(model, ids_a, backend)\n",
    "    vecs_b = get_unembed_vecs(model, ids_b, backend)\n",
    "\n",
    "    # Vector rejection: for each pair, remove the state-direction component\n",
    "    residuals = []\n",
    "    for va, vb in zip(vecs_a, vecs_b):\n",
    "        va_f, vb_f = va.float(), vb.float()\n",
    "        proj = (va_f @ vb_f) / (vb_f @ vb_f) * vb_f      # proj_{state}(capital)\n",
    "        residuals.append((va_f - proj).to(va.dtype))\n",
    "\n",
    "    direction = torch.stack(residuals).mean(0)\n",
    "\n",
    "    # Weight = average probability of group-A tokens, floored at 1e-6\n",
    "    probs = _get_last_position_probs(model, prompt)\n",
    "    avg_prob = max(sum(probs[i].item() for i in ids_a) / len(ids_a), 1e-6)\n",
    "\n",
    "    return CustomTarget(token_str=label, prob=avg_prob, vec=direction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Target Configuration\n",
    "\n",
    "Build the two custom targets and display a summary of all attribution configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the custom diff-target: logit(Austin) − logit(Dallas)\n",
    "custom_target, _, _ = build_custom_diff_target(\n",
    "    model, prompt, token_x, token_y, backend=backend\n",
    ")\n",
    "\n",
    "# Build the semantic concept target: Capital Cities − States\n",
    "capitals = [\"▁Austin\", \"▁Sacramento\", \"▁Olympia\", \"▁Atlanta\"]\n",
    "states   = [\"▁Texas\", \"▁California\", \"▁Washington\", \"▁Georgia\"]\n",
    "semantic_target = build_semantic_concept_target(\n",
    "    model, prompt, capitals, states,\n",
    "    label=\"Capitals − States\", backend=backend,\n",
    ")\n",
    "\n",
    "display_attribution_config(\n",
    "    token_pairs=[(token_x, idx_x), (token_y, idx_y), (\"▁Texas\", idx_texas)],\n",
    "    target_pairs=[(\"Logit diff\", custom_target), (\"Semantic concept\", semantic_target)],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EQuFE-eimS8m"
   },
   "source": [
    "### Logit Difference Target\n",
    "\n",
    "Pass a `CustomTarget` (or any `TargetSpec` — a tuple of `(token_str, prob, vec)`) that encodes a contrast direction in the residual stream. Here the direction is `logit(Austin) − logit(Dallas)`, constructing an attribution graph that more narrowly surfaces features driving the selection of the *correct* answer over the surface-level attractor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gMZ8Ee-KmS8m"
   },
   "outputs": [],
   "source": [
    "graph_custom = attribute(\n",
    "    prompt=prompt, model=model,\n",
    "    attribution_targets=[custom_target],\n",
    "    **attr_kwargs,\n",
    ")\n",
    "print(f\"Custom-target graph: {len(graph_custom.logit_targets)} targets, \"\n",
    "      f\"{graph_custom.active_features.shape[0]} active features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semantic Direction (Concept Target)\n",
    "\n",
    "Instead of a pairwise logit difference, we can attribute to an **abstract concept direction** in the residual stream. We build a `CustomTarget` via vector rejection: for each (capital, state) pair, project the capital vector onto the state vector and subtract that projection, leaving the pure 'capital-ness' component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_semantic = attribute(\n",
    "    prompt=prompt, model=model,\n",
    "    attribution_targets=[semantic_target],\n",
    "    **attr_kwargs,\n",
    ")\n",
    "print(f\"Semantic-target graph: {len(graph_semantic.logit_targets)} targets, \"\n",
    "      f\"{graph_semantic.active_features.shape[0]} active features\")\n",
    "\n",
    "# Free CUDA memory before feature comparison\n",
    "cleanup_cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yDGiO8jBmS8m"
   },
   "source": [
    "## Compare Top Features\n",
    "\n",
    "Extract the top-10 features from each graph (ranked by multi-hop influence) and display them side by side. Feature indices link to their [Neuronpedia](https://www.neuronpedia.org/) dashboards. The *Custom Target* column highlights features that specifically drive the Austin-vs-Dallas logit difference — the multi-hop reasoning circuit (Dallas → Texas → capital → Austin). The *Concept Target* column surfaces features associated with the more general *capital-of* relation, which partially overlaps with the multi-hop chain but also includes distinct features that may reflect more abstract capital-related reasoning.\n",
    "\n",
    "> **Note:** The `torch.Tensor` target example is omitted from this comparison because it uses the same token IDs as the `Sequence[str]` example — the resulting graphs are identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "185O1Ck1mS8m"
   },
   "outputs": [],
   "source": [
    "top_salient, scores_salient   = get_top_features(graph_salient,  n=10)\n",
    "top_str, scores_str           = get_top_features(graph_str,      n=10)\n",
    "top_custom, scores_custom     = get_top_features(graph_custom,   n=10)\n",
    "top_semantic, scores_semantic = get_top_features(graph_semantic,  n=10)\n",
    "\n",
    "display_top_features_comparison(\n",
    "    {\n",
    "        \"Salient Logits\": top_salient,\n",
    "        f\"Strings [{token_x}, {token_y}]\": top_str,\n",
    "        f\"Custom Fn ({custom_target.token_str})\": top_custom,\n",
    "        f\"Semantic Concept ({semantic_target.token_str})\": top_semantic,\n",
    "    },\n",
    "    scores_sets={\n",
    "        \"Salient Logits\": scores_salient,\n",
    "        f\"Strings [{token_x}, {token_y}]\": scores_str,\n",
    "        f\"Custom Fn ({custom_target.token_str})\": scores_custom,\n",
    "        f\"Semantic Concept ({semantic_target.token_str})\": scores_semantic,\n",
    "    },\n",
    "    neuronpedia_model=\"gemma-2-2b\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Circuit Interventions\n",
    "\n",
    "Having identified the top features for each attribution mode example, we can now run interventions, manipulating the discovered features to bolster our credence in their hypothesized causal roles. We explore both amplification and ablation of the logit-difference and semantic concept circuits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "98579UbGmS8m"
   },
   "source": [
    "### Amplify the Austin-Dallas Logit Difference Circuit\n",
    "\n",
    "To confirm these custom-target features are causally meaningful, we amplify them by 10× and check that the Austin-vs-Dallas logit gap widens (i.e., the model becomes even more confident Austin is correct)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get activations for interventions\n",
    "input_ids = model.ensure_tokenized(prompt)\n",
    "original_logits, activations = model.get_activations(input_ids, sparse=True)\n",
    "\n",
    "# Baseline\n",
    "display_token_probs(original_logits, key_ids, key_labels, title=\"Before amplification\")\n",
    "\n",
    "# Amplify top custom-target features by 10×\n",
    "intervention_tuples = [\n",
    "    (layer, pos, feat_idx, 10.0 * activations[layer, pos, feat_idx])\n",
    "    for (layer, pos, feat_idx) in top_custom\n",
    "]\n",
    "\n",
    "new_logits, _ = model.feature_intervention(input_ids, intervention_tuples)\n",
    "\n",
    "display_token_probs(new_logits, key_ids, key_labels, title=\"After 10× amplification\")\n",
    "\n",
    "orig_gap = (original_logits.squeeze(0)[-1, idx_x] - original_logits.squeeze(0)[-1, idx_y]).item()\n",
    "new_gap = (new_logits.squeeze(0)[-1, idx_x] - new_logits.squeeze(0)[-1, idx_y]).item()\n",
    "print(f\"\\nlogit(Austin) − logit(Dallas): {orig_gap:.4f} → {new_gap:.4f}  (Δ = {new_gap - orig_gap:+.4f})\")\n",
    "\n",
    "display_topk(prompt, original_logits, new_logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amplify the Semantic Concept Circuit\n",
    "\n",
    "Same amplification test for the **semantic concept** features. We compare a modest 2× boost (a gentle nudge along the concept axis) with a strong 10× boost to observe the difference in behaviour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline\n",
    "display_token_probs(original_logits, key_ids, key_labels, title=\"Before amplification (semantic)\")\n",
    "\n",
    "orig_gap = (original_logits.squeeze(0)[-1, idx_x] - original_logits.squeeze(0)[-1, idx_y]).item()\n",
    "\n",
    "# --- 2× amplification (gentle nudge along the concept axis) ---\n",
    "sem_amp_tuples_2 = [\n",
    "    (layer, pos, feat_idx, 2.0 * activations[layer, pos, feat_idx])\n",
    "    for (layer, pos, feat_idx) in top_semantic\n",
    "]\n",
    "\n",
    "sem_amp_logits_2, _ = model.feature_intervention(input_ids, sem_amp_tuples_2)\n",
    "\n",
    "display_token_probs(sem_amp_logits_2, key_ids, key_labels, title=\"After 2× amplification (semantic)\")\n",
    "\n",
    "sem_gap_2 = (sem_amp_logits_2.squeeze(0)[-1, idx_x] - sem_amp_logits_2.squeeze(0)[-1, idx_y]).item()\n",
    "print(f\"\\nlogit(Austin) − logit(Dallas): {orig_gap:.4f} → {sem_gap_2:.4f}  (Δ = {sem_gap_2 - orig_gap:+.4f})  [2×]\")\n",
    "\n",
    "display_topk(prompt, original_logits, sem_amp_logits_2)\n",
    "\n",
    "# --- 10× amplification (strong boost) ---\n",
    "sem_amp_tuples_10 = [\n",
    "    (layer, pos, feat_idx, 10.0 * activations[layer, pos, feat_idx])\n",
    "    for (layer, pos, feat_idx) in top_semantic\n",
    "]\n",
    "\n",
    "sem_amp_logits_10, _ = model.feature_intervention(input_ids, sem_amp_tuples_10)\n",
    "\n",
    "display_token_probs(sem_amp_logits_10, key_ids, key_labels, title=\"After 10× amplification (semantic)\")\n",
    "\n",
    "sem_gap_10 = (sem_amp_logits_10.squeeze(0)[-1, idx_x] - sem_amp_logits_10.squeeze(0)[-1, idx_y]).item()\n",
    "print(f\"\\nlogit(Austin) − logit(Dallas): {orig_gap:.4f} → {sem_gap_10:.4f}  (Δ = {sem_gap_10 - orig_gap:+.4f})  [10×]\")\n",
    "\n",
    "display_topk(prompt, original_logits, sem_amp_logits_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ablate the Austin-Dallas Logit Difference Circuit\n",
    "\n",
    "Now we do the opposite: zero out progressively more features important to our custom target to dampen the Austin-driving circuit. With enough of the multi-hop reasoning path suppressed, the model can no longer resolve the correct answer and reverts to nearby concepts — e.g. the intermediate state (Texas) rather than its capital."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "# Progressive ablation: zero out increasing numbers of custom-target features\n",
    "probs_base = torch.softmax(original_logits.squeeze(0)[-1].float(), dim=-1)\n",
    "groups = {\"baseline\": {\n",
    "    \"P(Austin)\": probs_base[idx_x].item(),\n",
    "    \"P(Dallas)\": probs_base[idx_y].item(),\n",
    "    \"P(Texas)\":  probs_base[idx_texas].item(),\n",
    "}}\n",
    "logit_diffs = {\"baseline\": orig_gap}\n",
    "\n",
    "ablation_results = {}\n",
    "for n in [10, 100]:\n",
    "    top_n, _ = get_top_features(graph_custom, n=n)\n",
    "    abl_tuples = [\n",
    "        (layer, pos, feat_idx, 0.0 * activations[layer, pos, feat_idx])\n",
    "        for (layer, pos, feat_idx) in top_n\n",
    "    ]\n",
    "    abl_logits, _ = model.feature_intervention(input_ids, abl_tuples)\n",
    "    probs_abl = torch.softmax(abl_logits.squeeze(0)[-1].float(), dim=-1)\n",
    "    gap = (abl_logits.squeeze(0)[-1, idx_x] - abl_logits.squeeze(0)[-1, idx_y]).item()\n",
    "    label = f\"top-{n}\"\n",
    "    groups[label] = {\n",
    "        \"P(Austin)\": probs_abl[idx_x].item(),\n",
    "        \"P(Dallas)\": probs_abl[idx_y].item(),\n",
    "        \"P(Texas)\":  probs_abl[idx_texas].item(),\n",
    "    }\n",
    "    logit_diffs[label] = gap\n",
    "    ablation_results[n] = abl_logits\n",
    "\n",
    "display_ablation_chart(groups, logit_diffs=logit_diffs,\n",
    "                       title=\"Custom-target ablation: token probabilities & logit gap\")\n",
    "\n",
    "# Show the full top-k comparison for the strongest ablation\n",
    "strongest_n = max(ablation_results.keys())\n",
    "display(Markdown(f\"#### Top-{strongest_n} ablation — full prediction shift\"))\n",
    "display_topk(prompt, original_logits, ablation_results[strongest_n])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ablate the Semantic Concept Circuit\n",
    "\n",
    "Same progressive ablation, now zeroing out features from the **semantic concept** graph. Because the concept direction captures the capital-vs-state pathway, ablation should similarly collapse the Austin signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "# Progressive ablation of semantic-target features\n",
    "sem_groups = {\"baseline\": {\n",
    "    \"P(Austin)\": probs_base[idx_x].item(),\n",
    "    \"P(Dallas)\": probs_base[idx_y].item(),\n",
    "    \"P(Texas)\":  probs_base[idx_texas].item(),\n",
    "}}\n",
    "sem_logit_diffs = {\"baseline\": orig_gap}\n",
    "\n",
    "sem_ablation_results = {}\n",
    "for n in [10, 100]:\n",
    "    top_n, _ = get_top_features(graph_semantic, n=n)\n",
    "    abl_tuples = [\n",
    "        (layer, pos, feat_idx, 0.0 * activations[layer, pos, feat_idx])\n",
    "        for (layer, pos, feat_idx) in top_n\n",
    "    ]\n",
    "    abl_logits, _ = model.feature_intervention(input_ids, abl_tuples)\n",
    "    probs_abl = torch.softmax(abl_logits.squeeze(0)[-1].float(), dim=-1)\n",
    "    gap = (abl_logits.squeeze(0)[-1, idx_x] - abl_logits.squeeze(0)[-1, idx_y]).item()\n",
    "    label = f\"top-{n}\"\n",
    "    sem_groups[label] = {\n",
    "        \"P(Austin)\": probs_abl[idx_x].item(),\n",
    "        \"P(Dallas)\": probs_abl[idx_y].item(),\n",
    "        \"P(Texas)\":  probs_abl[idx_texas].item(),\n",
    "    }\n",
    "    sem_logit_diffs[label] = gap\n",
    "    sem_ablation_results[n] = abl_logits\n",
    "\n",
    "display_ablation_chart(sem_groups, logit_diffs=sem_logit_diffs,\n",
    "                       title=\"Semantic-target ablation: token probabilities & logit gap\")\n",
    "\n",
    "# Show the full top-k comparison for the strongest ablation\n",
    "strongest_n = max(sem_ablation_results.keys())\n",
    "display(Markdown(f\"#### Top-{strongest_n} semantic ablation — full prediction shift\"))\n",
    "display_topk(prompt, original_logits, sem_ablation_results[strongest_n])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IGnU9l1zmS8m"
   },
   "source": [
    "## Visualize the Semantic Concept Graph\n",
    "\n",
    "Save the **semantic concept** graph and serve it locally. The interactive visualization shows the circuit driving the abstract `Capitals − States` direction — the multi-hop reasoning path.\n",
    "\n",
    "**If running on a remote server, set up port forwarding so that port 8046 is accessible on your local machine.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "graph_dir = Path(\"attribution_targets_demo/graphs\")\n",
    "graph_dir.mkdir(parents=True, exist_ok=True)\n",
    "graph_path = graph_dir / \"dallas_austin_semantic_concept_graph.pt\"\n",
    "graph_semantic.to_pt(graph_path)\n",
    "\n",
    "slug = \"dallas-austin-semantic-concept\"\n",
    "graph_file_dir = \"attribution_targets_demo/graph_files\"\n",
    "node_threshold, edge_threshold = 0.8, 0.98\n",
    "\n",
    "create_graph_files(\n",
    "    graph_or_path=graph_path,\n",
    "    slug=slug,\n",
    "    output_path=graph_file_dir,\n",
    "    node_threshold=node_threshold,\n",
    "    edge_threshold=edge_threshold,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GmKhWpuUmS8n"
   },
   "outputs": [],
   "source": [
    "from circuit_tracer.frontend.local_server import serve\n",
    "\n",
    "port = 8046\n",
    "server = serve(data_dir=\"attribution_targets_demo/graph_files/\", port=port)\n",
    "\n",
    "if IN_COLAB:\n",
    "    from google.colab import output as colab_output  # noqa\n",
    "    colab_output.serve_kernel_port_as_iframe(\n",
    "        port, path=\"/index.html\", height=\"800px\", cache_in_notebook=True\n",
    "    )\n",
    "else:\n",
    "    from IPython.display import IFrame\n",
    "    print(f\"Open your graph at: http://localhost:{port}/index.html\")\n",
    "    display(IFrame(src=f\"http://localhost:{port}/index.html\", width=\"100%\", height=\"800px\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uCo4FSQwqcBl"
   },
   "outputs": [],
   "source": [
    "# server.stop()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ct_dev (3.13.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
